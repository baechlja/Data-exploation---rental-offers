{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecfd49dc",
   "metadata": {},
   "source": [
    "# Data Exploration Rental Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8535b430",
   "metadata": {},
   "source": [
    "### General Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4936b66",
   "metadata": {},
   "source": [
    "<p>\n",
    "    The Business Usecase is:<br>\n",
    "    <ul>\n",
    "        <li>Prediced the Rental Pricing in Germany</li>\n",
    "        <li>What kind of Featurs are the most importaned for a Rental Object</li>\n",
    "        <li>How important is the Geo Location for the Rental Object</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6edc26",
   "metadata": {},
   "source": [
    "### General Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5e7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import urllib.parse\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019d3a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data \n",
    "path = \"immo_data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45de3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for the Code\n",
    "\n",
    "#creates a Correlation Matrix\n",
    "def correlation_matrix(df):\n",
    "    corr = df.corr()\n",
    "    f, ax = plt.subplots(figsize=(20, 20))\n",
    "    sns.heatmap(corr, square = True,fmt='.2f' ,annot = True)\n",
    "    \n",
    "#Creates a Mean for one Dataframe Attribute\n",
    "def set_maker(df,attribute):\n",
    "    array = df[attribute].unique()\n",
    "    help_list = array.tolist()\n",
    "    attribute_set = set(help_list)\n",
    "    print(attribute_set)\n",
    "    if type(help_list[1]) == int or float:\n",
    "        print(\"The mean of this Attribute is {}\".format(df[attribute].mean()))\n",
    "    elif type(help_list[1]) == str:\n",
    "        print(\"Sorry there is no mean to figute out.\")\n",
    "\n",
    "#Drops Inappropriate Data of one specific Value\n",
    "def drop_inappropriate(df, attribute, value):\n",
    "    i = df[df[attribute] == value].shape[0]\n",
    "    print(\"There are {} inappropriate Data Points with the Value {}\".format(i,value))\n",
    "    df = df.drop(df[df[attribute] == value].index)\n",
    "    print(\"The Datapiont have been Droped, the shape if the Dataframe is now {}\".format(df.shape))\n",
    "    return df\n",
    "\n",
    "#Drops Inappropriate Data that is bigger than a specific Value\n",
    "def drop_inappropriate_bigger(df, attribute, value):\n",
    "    i = df[df[attribute] >= value].shape[0]\n",
    "    print(\"There are {} inappropriate Data Points with the Value bigger than {}\".format(i,value))\n",
    "    df = df.drop(df[df[attribute] >= value].index)\n",
    "    print(\"The Datapiont have been Droped, the shape if the Dataframe is now {}\".format(df.shape))\n",
    "    return df\n",
    "\n",
    "#Drops Inappropriate Data that is bigger than a specific Value\n",
    "def drop_inappropriate_smaller(df, attribute, value):\n",
    "    i = df[df[attribute] <= value].shape[0]\n",
    "    print(\"There are {} inappropriate Data Points with the Value smaller than {}\".format(i,value))\n",
    "    df = df.drop(df[df[attribute] <= value].index)\n",
    "    print(\"The Datapiont have been Droped, the shape if the Dataframe is now {}\".format(df.shape))\n",
    "    return df\n",
    "\n",
    "#Returns the all Column Names that have Categorial Data \n",
    "def get_categorical_cols(df):\n",
    "    categorical_columns = []\n",
    "    for cols in df.columns:\n",
    "        if df[cols].dtype == 'object':\n",
    "            categorical_columns.append(cols)\n",
    "    return categorical_columns\n",
    "        \n",
    "#Creates a Dict with Weights and Names of  Prediction\n",
    "def get_weight_dict(df, target_var, model):\n",
    "    columns = []\n",
    "    for cols in df.columns:\n",
    "        columns.append(cols)\n",
    "    columns.remove(target_var)\n",
    "    if model == tree or random_forest:\n",
    "        weights = model.feature_importances_\n",
    "    else:\n",
    "        weights = model.coef_\n",
    "    weights_dictionary = dict(zip(columns, weights))\n",
    "    return{k: v for k, v in sorted(weights_dictionary.items(), key=lambda item: item[1], reverse=True)}\n",
    " \n",
    "#Makes a Histogram\n",
    "def pd_hist(df,bins,attribute=False):\n",
    "    if bool(attribute) == True:\n",
    "        test_df = df[attribute]\n",
    "        hist = test_df.hist(bins=bins,figsize=(20,20))\n",
    "    else:\n",
    "        hist = df.hist(bins=bins,figsize=(20,20))\n",
    "\n",
    "#Feature Scales the hole Dataframe\n",
    "def feature_scaling(df):\n",
    "    scaler = MaxAbsScaler()\n",
    "    # calculate the maximum absolute value\n",
    "    scaler.fit(df)\n",
    "    scaler.max_abs_\n",
    "    # transform the data using the parameters calculated by the fit method\n",
    "    scaled_data = scaler.transform(df)\n",
    "    df_scaled = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "    return df_scaled\n",
    "\n",
    "#Changes Categorical Data to Numbers\n",
    "def change_categorical(df):\n",
    "    cat = get_categorical_cols(df)\n",
    "    cat_df = df[cat]\n",
    "    df = df.drop(columns=cat)\n",
    "    cat_df = cat_df.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "    df =  pd.concat([df, cat_df], axis=1)\n",
    "    #df = df.append(cat_df, ignore_index=True)\n",
    "    #f_all = [df, cat_df]    , ignore_index=True\n",
    "    #esult = pd.concat(df_all)\n",
    "    return df\n",
    "\n",
    "#\n",
    "def displot(df, x, y):\n",
    "    sns.displot(data=df, x=df[y], col=df[x], kde=True)\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b080173",
   "metadata": {},
   "source": [
    "### First Look into the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01fb465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed4364",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e266f283",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7c705",
   "metadata": {},
   "source": [
    "### Handeling Null Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect how much Null Data there is\n",
    "df.isna().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418dc550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See how many Attributes have more than 50% Null Data\n",
    "df.columns[((df.isna().sum()/len(df)) > 0.50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking deeper into each Attribute with more than 50% Null Data\n",
    "    #set_maker(df,\"noParkSpaces\")\n",
    "    #df['noParkSpaces'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10235c8",
   "metadata": {},
   "source": [
    "<br>\n",
    "<ul>\n",
    "    <li>telekomHybridUploadSpeed = 83% null (to much null to set with mean and no real corelation to price)\n",
    "    <li>noParkSpaces = 65% (Will be replaced with 0)\n",
    "    <li>heatingCosts = 68% (Is know from previos owners and will be sett to mean because in a test is brought 1-2% of accuracy)\n",
    "    <li>energyEfficiencyClass = 71% (To little Corelation and to many missing)\n",
    "    <li>lastRefurbish = 70% (A lot of wrong Data and a hight rate if Nan will be cut)\n",
    "    <li>electricityBasePrice = 82% (Sind seit 2020 veraltet, und viele Fehlende Daten, will be cut)\n",
    "    <li>electricityKwhPrice = 82% (Cut out, small range of Values and to many Nan)\n",
    "</ul>\n",
    "<p> The only Attribute that stays from the list will be no of Parking Spaces\n",
    "    <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drops Colums with to much Null\n",
    "df = df.drop(columns=df.columns[((df.isna().sum()/len(df)) > 0.69)])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b341f",
   "metadata": {},
   "source": [
    "### Handeling inappropriat Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974be489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since No. of Parkingspaces are importat for a Arppartmet I think they would put them in the offering\n",
    "#seting noParkings. from Nan to 0\n",
    "df[\"noParkSpaces\"] = df[\"noParkSpaces\"].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Data pionts in \"baseRent\" with the Values 0.0\n",
    "df = drop_inappropriate(df,\"baseRent\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f9e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Data pionts in \"livingSpace\" with the Values 0.0\n",
    "df = drop_inappropriate(df,\"livingSpace\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12cdb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Data pionts in \"floor\" with the Values bigger than 50\n",
    "#there are no rental objects higher than 50 floors\n",
    "df = drop_inappropriate_bigger(df,\"floor\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a83bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Data pionts in \"numberOfFloors\" with the Values bigger than 50\n",
    "#there are no rental objects higher than 50 floors\n",
    "df = drop_inappropriate_bigger(df,\"numberOfFloors\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19069490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Data pionts in \"noParkSpaces\" with the Values bigger than 30\n",
    "df = drop_inappropriate_bigger(df,\"noParkSpaces\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_inappropriate_bigger(df,\"serviceCharge\", 1000)\n",
    "df = drop_inappropriate_smaller(df,\"serviceCharge\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e1e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To big for the Client\n",
    "df = drop_inappropriate_bigger(df,\"livingSpace\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f90ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To big for the Client\n",
    "df = drop_inappropriate_bigger(df,\"noRooms\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a4fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Data pionts in \"baseRent\" with the Values bigger than 10.000â‚¬\n",
    "#To expencive for the Client\n",
    "df = drop_inappropriate_bigger(df,\"baseRent\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb74086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not realistic\n",
    "df = drop_inappropriate_bigger(df,\"heatingCosts\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To old for the Client\n",
    "df = drop_inappropriate_smaller(df,\"yearConstructed\", 1900) #1900\n",
    "df = drop_inappropriate_bigger(df,\"yearConstructed\", 2025) #2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaeef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is important on witch floor the flat is as long as it's not on 0 (ground Floor) so every Nan will be replaced with 0 \n",
    "#because taking a mean or median would not make sence\n",
    "#some people have put 1 for the ground floor and some 0 soo? What to do?\n",
    "df[\"floor\"] = df[\"floor\"].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will be changes to numbers so all Methods can work with it\n",
    "df[\"petsAllowed\"] = df[\"petsAllowed\"].fillna(value='no')\n",
    "df[\"petsAllowed\"] = df[\"petsAllowed\"].replace(['no'],0)\n",
    "df[\"petsAllowed\"] = df[\"petsAllowed\"].replace(['negotiable'],5)\n",
    "df[\"petsAllowed\"] = df[\"petsAllowed\"].replace(['yes'],10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b186f497",
   "metadata": {},
   "source": [
    "### Drop not usefull Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b046f",
   "metadata": {},
   "source": [
    "<h4> Explanation why they are not Usefull</h4>\n",
    "    <ul>\n",
    "        <li>description = No need because there are no direct information on the House Price, could be explord in side Project\n",
    "        <li>livingSpaceRange = Is reprecented in other Attributes.\n",
    "        <li>scoutId = Just a Immoscout intern ID\n",
    "        <li>street = Not importat\n",
    "        <li>streetPlain = Same as Steet Name\n",
    "        <li>houseNumber = Not important\n",
    "        <li>date = Just the scraping date.\n",
    "        <li>facilities = Same as Description\n",
    "        <li>totalRent = is just a combination of Rent and serviceCharges, still has no correlation\n",
    "        <li>telekomUploadSpeed = Has no Corralation and makes no sens to keep everyone can choose the Speed they want to pay for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Attributes that are unimportant \n",
    "df = df.drop(columns=['description','livingSpaceRange','scoutId','street','streetPlain','houseNumber','date','facilities','totalRent','telekomUploadSpeed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203abaa",
   "metadata": {},
   "source": [
    "### Fill Numeric Null with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the mean of the Data\n",
    "df._get_numeric_data().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f792441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the Nan with mean\n",
    "df.fillna(df._get_numeric_data().mean(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the remaining Null Values\n",
    "df._get_numeric_data().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b65ca11",
   "metadata": {},
   "source": [
    "### The Categorical Data will be handelt in the Prediction part because it's better to Visualiz this way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f23cbf",
   "metadata": {},
   "source": [
    "## 2. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294827c",
   "metadata": {},
   "source": [
    "### General Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4745f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_hist(df,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee18f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9825bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981df25",
   "metadata": {},
   "source": [
    "### Development of rental prices in relation to the variables with the highest correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d7b39",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Living Space \n",
    "    <li> Service Charge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3545f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='livingSpace', y='baseRent', data=df, scatter_kws={\"alpha\":0.3,\"s\":20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db15e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = 'serviceCharge', y= 'baseRent', data=df, scatter_kws={\"alpha\":0.3,\"s\":20})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59252c",
   "metadata": {},
   "source": [
    "### Rental prices in comparison of the German states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a5f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "sns.barplot(x=df.regio1, y=df.baseRent, ci = None)\n",
    "plt.ylim([25, 1250])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6ac42",
   "metadata": {},
   "source": [
    "## 3. Data Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff59106d",
   "metadata": {},
   "source": [
    "### Handeling Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changes the Categorical Data to Numbers\n",
    "df = change_categorical(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51223d6a",
   "metadata": {},
   "source": [
    "### Additional (specialy needed for KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f38964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replaces bool with numbers otherwise the featurescaling would not work\n",
    "bool_list = [\"newlyConst\", \"balcony\", \"hasKitchen\", \"cellar\", \"lift\" , \"garden\" ]\n",
    "for x in bool_list:\n",
    "    df[x] = df[x].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5ed071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_scaling(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89478e91",
   "metadata": {},
   "source": [
    "### General prediction preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381848a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the sklearn libarys \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4150219",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.copy()\n",
    "y = df['baseRent']  #np.log() #with the log the prediction score gets better, but we found no usecase for that\n",
    "\n",
    "X.drop(['baseRent'],axis=1,inplace = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a73ec",
   "metadata": {},
   "source": [
    "### Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineReg = LinearRegression()\n",
    "lineReg.fit(X_train, y_train)\n",
    "\n",
    "prediction = lineReg.predict(X_test)\n",
    "#f1_score = f1_score(y_test, prediction, average='micro')\n",
    "\n",
    "print('Score: ', lineReg.score(X_test, y_test))\n",
    "#print('F1 Score: ', f1_score)\n",
    "\n",
    "\n",
    "plt.plot(predict)\n",
    "plt.show()\n",
    "plt.plot(y_test)\n",
    "plt.show()\n",
    "\n",
    "print(\"Weights:\")\n",
    "get_weight_dict(df, 'baseRent', lineReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b312474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.Ridge (alpha = .001)\n",
    "reg.fit(X_train, y_train)\n",
    "print('Score: ', reg.score(X_test, y_test))\n",
    "\n",
    "\n",
    "plt.plot(reg.predict(X_test))\n",
    "plt.plot(y_test)\n",
    "plt.show()\n",
    "\n",
    "print(\"Weights:\")\n",
    "get_weight_dict(df, 'baseRent', reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d51254",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD = linear_model.SGDRegressor(alpha = 0.001)\n",
    "SGD.fit(X_train, y_train)\n",
    "print('Score: ', SGD.score(X_test, y_test))\n",
    "\n",
    "plt.plot(SGD.predict(X_test))\n",
    "plt.plot(y_test)\n",
    "plt.show()\n",
    "\n",
    "print(\"Weights:\")\n",
    "get_weight_dict(df, 'baseRent', SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43740a",
   "metadata": {},
   "source": [
    "### Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=10)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print('Score: ', tree.score(X_test, y_test))\n",
    "\n",
    "\n",
    "plt.plot(tree.predict(X_test))\n",
    "plt.plot(y_test)\n",
    "plt.show()\n",
    "\n",
    "print(\"Weights:\")\n",
    "get_weight_dict(df, 'baseRent',tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7d81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestRegressor(max_depth=15, random_state=0)\n",
    "random_forest.fit(X_train, y_train)\n",
    "print('Score: ', random_forest.score(X_test, y_test))\n",
    "\n",
    "plt.plot(random_forest.predict(X_test))\n",
    "plt.plot(y_test)\n",
    "plt.show()\n",
    "\n",
    "print(\"Weights:\")\n",
    "get_weight_dict(df, 'baseRent',random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e390a12",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883cdc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor(n_neighbors=3)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "print('Score: ', knn_model.score(X_test, y_test))\n",
    "\n",
    "\n",
    "plt.plot(knn_model.predict(X_test))\n",
    "plt.plot(y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45aa3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7d38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d4e440d",
   "metadata": {},
   "source": [
    "## 4. Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6271a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Location Dataframe\n",
    "path_plz = \"plz_geocoord.csv\"\n",
    "df_plz = pd.read_csv(path_plz)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_plz.columns = ['plz', 'lat', 'lon']\n",
    "df_plz = df_plz.set_index('plz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69305a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "df = df.merge(df_plz, how='inner', on='geo_plz')\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "\n",
    "print(\"It took {} Sec. to get {} Lat and Lon Data Pionts\".format(total,df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68364a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "fp = \"geomap/vg2500_bld.shp\"\n",
    "map_df = gpd.read_file(fp)\n",
    "map_df.head()\n",
    "map_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e63083",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df['lon'], y=df['lat'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
